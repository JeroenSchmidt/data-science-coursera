---
typora-copy-images-to: Images
---

# R Language

[TOC]

## Environment Basics

1. R Language
2. R tools (for windows)
3. R Studio

### Basic Commands

```R
# Get Working Directory
getwd()

# Changing Working Directory
setwd("<directory address>")

# See contents in working directory
dir()

#Load R file
source("<file name>")

# See loaded functions
ls

# Getting help
?<|Command name|>
# for operatiors
?"<|Command name|>"
```

**Note**: every time you make a change to an R file you need to reload it with `source`

## Draw Backs

- Little 3-D graphics support
- Functionality is based on consumer demand
- Wasn't created with parallel computing in mind
- Objects must be stored in physical memory.
  - Work abounds exist

## R Design

**Two Parts**

1. Base R  - controlled by the *CORE group*
2. Everything Else

*Base R Packages*  

`utils`,`stats`,`datasets`,`graphics`,`grDevices`,`grid`,`methods`,`tools`

,`parallel`,`comiler`,`splines`,`tcltk`,`stats4` 

*Recommended Packages*

`boot`, `class`, `cluster`, `codetools`, `foreign`, `KernSmooth`, `lattice`,`mgcv`,`nime`,`rpart`,`survival`,`MASS`,`spatial`,`nnet`,`Matrix`

***NOTE:***

There are +4000 packages on CRAN. These packages are not controlled by the core group, but CRAN has certain standards that need to be meet for a package to be included on CRAN. $\rightarrow$ quality 

## Resources

*Literature:* [List of books for R](http://www.r-project.org/doc/bib/R-books.html)

*Mailing list:* [r-help@r-project.org](mailto:r-help@r-project.org)

### Asking questions

- What steps will reproduce the problem?
- What is the expected output?
- What do you see instead?
- What version of the product(R,packages, etc) are you using?
- OS?
- Additional info?

*Question Examples*

![img](Images\Capture.png)

*How to:*

- Describe the goal
- Explicit in question
  - min amount of information 


## Data types

### 5 atomic objects

1. character
2. numeric
3. interger
4. complex
5. boolean / logical

***Numbers***

```R
# Explicit declaration of an Integer
x <- 1L
```

*Infinity (i.e. $\frac{1}{0}$)*

```R
Inf
```

*NaN (i.e. $0.0$)*

```R
NaN
```
### Object Attributes

All objects contain the following attributes

1. Names , dimnames
2. dimensions
3. class
4. length
5. other meta data

```R
# Attributes can be set/modified via
attributes()
```
### Vector object

- Can only contain objects of the same class
- `List` can contain objects of different classes

*Creating Vectors*

```R
x <- c(item1,item2, etc)
```

Empty vector

```R
x <- vector(<|"data_type"|>, length = #length)
```


*Mixing Objects:* Coercion occurs s.t. every element in the vector is of the same class.

*Explicit Coercion:* Converts the variable from one data type to another

```R
as.<|data_type|>
```

***NOTE:*** When coercion is done, there are cases where a conversion is successfully executed but not necessarily correct.

```R
> x <- c("a","b","c")
> as.numeric(x)
> [1] NA NA NA
> Warning Message
```

### Lists

Lists are a type of vector that contains elements of different classes

```R
# Declaring a list
x <- list(object1,object2,object3) 
```

### Matrix

==NOTE:== Many ways to declare a matrix

```R
# Declare a matrix
m <- matrix(nrow = 2, ncol = 3)
```

```R
# Dimension of matrix
dim(#matrix)
#OR
attributes(<|matrix|>)  
```

**Construction**
Matrices are constructed colum-wise. Start at (1,1) and run down the columns.

```R
> m <- matrix(1:6, nrow=2, ncol=3)
> m
     [,1] [,2] [,3]
[1,]    1    3    5
[2,]    2    4    6
```

**Direct Construction**
Create a vector, then add the dimension attribute which changes it to a matrix. 

```R
m <- 1:10
dim(m) <- c(2,5)
```

**Bind Construction**
1) *Column binding*
Constructs columns by putting vectors next to each other as coloumns

```R
cbind(<|vector1|>,<|vector2|>)
```

*2) Row binding*
Constructs columns by putting vectors ontop of each other as rows

```R
rbind(|<vector1|>,<|vector2|>)
```

### Factors

Represent categorical data. Can be ordered / unordered.
Think of a factor being an integer vector; each integer assigned a label *(refered to as levels)*

Modeling functions like:

- `lm()` - linear model
- `glm()` - general linear model

```R
#Count label
table(#factor)
```

```R
#Separate the object into its components
unclass()
# Note: In the case of factors; itll show you the underlaying integer vector and the label mapping.
```

```R
#Declaring levels(labels)
x <- factors(c("yes","no","yes"), levels = c("yes","no"))
```

*==NOTE:==* In the background factors automatically assigned the level according to alphabetical order. By declaring the *levels* like this we are telling R to start with "yes".

## Missing Values

```R
# Undefined math operations
NaN
```

```R
#Everything Else
Na
```

### Logic & Cavets

```R
is.na()
is.nan()
```

==NOTE:== 

- NA also has a class 
  - ie NA could look the same but actually isn't the same type of NA under the hood
  - NA (int) vs NA (String)
- NaN is a NA but NA is not a NaN

## DataFrame

Used to store tabular data

Each col is a different object

```R
# Convert DataFrame to Matrix
data.matrix()
#NOTE: Forces each object to be the same
```

```R
#Declaring a Dataframe
x <- data.frame(col1 = #vector, col2= #vector)
```

```R
# Declaring Dataframe row names
rownames(x) <- <vector with row names>
```

```R
# Otherways to create dataframes
read.table()
# OR
read.csv()
```

### Reading from DataFrames

*DataFrame coloumns*

```R
x <- data.frame(col1 = <values>, col2 = <values>)

# return a vector of values stored in col1
x$col1
#or
x[["col1"]]

# return dataframe with col values
x["col1"]
```

*DataFrame rows*

```R
x <- data.frame(col1 = <values>, col2 = <values>)

# return 1st row using default row names
x[1,]

# return assigend row names
rownames <- 11:20
x["11",]
```

## Name Attributes

```R
# Naming vector entries
x <- vector()
names(x) <- c("name1","name2",...)
```

```R
# Naming list entries
x <- lsit(a=1,b=2,c=3)
# Item 1 is called a, item 2 is called b, etc
```

**Naming Matrix - dimnames**

```R
m <- matrixdimnames(m) <- list(c("row1","row2"), c("col1","col2"))
```

## Reading Data

```R
# Tabluar data
read.table
```

- skips lines with #
- figure out variable types
- CAN specify arguments

```R
read.csv
# Identical to read.table but default separator is a comma
```

```R
# Reading lines of a text file
readLines
```

```R
# Reading R code files
source
```

```R
# Reading R code files - specifically R objects
dget
```

```R
# Reading saved workspaces
load
```

```R
# Reading sinlge R object in binary form
unserialize
```

## Textual Formats 

```R
# Output Textual format 
dumping
# OR
dputing

# Outputs all data including meta-data
```

NOTE: 

- Textual data works well with version controle - good way of keeping track of meta changes
- Easier to fix corruptions
- Not space efficiency

**dput function**

```R
> dput(#object,file="#file_name.R")
# Can only be used on a single R object
```

```R
# Reading dput
> new.y <- dget("#file_name.R")
```

**dump function**

```R
> dump(c("object1","object2"), file = "file_name.R"
```

```R
# reading dump
> source("file_name.R")
```

## Interfacing with outside world

**Some basic connections**

```R
file()
gzfile()
bzfile()
url()
```

**Connection Interface**

Usually we don't need to directly deal with the connection interface. But when dealing with non-standard inputs, using a connection interface can be useful. 

```R
> con <- url("#url", "r")
> x <- readLines(con)
> head(x)
```

## Subsettings

Return one or more element of the same class

```R
1) x[#item_number]
2) x[#lower:#upper]
```

```R
# Extract single element
x[[]]
```

```R
# Logical subsetting
x[#logic_object]
```

```R
# Logic object
u <- x > 3
```

### Subsetting Lists

```R
x <- list(foo = 1:4, bar = 0.6)
```

```R
# Returns a list with the values 
x[1]
# same as
x["foo"]
```

**Returns just the values**

```R
x[[1]]
```

```R
x$bar 
# the same
asx[["bar"]]
```

```R
# Returing multiple entires
x(c(#lower,#upper))
```

**`$` vs `[[]]`** 

- `$` works for literal names
- `[[]]` works on computed name
  - ie you can use a variable containing names

**Reading nested Lists**

```R
#Reading nested Lists
> x <- list(a = list(10,12,14), b=c(3.14, 2.81))

x[[c(1,3)]]
> 14

x[1]]
> 14
```

### Subsetting Matrices

**Single Elements**

```R
# Return element by row/col coordinate
x[#row,#col]
```

```R
# Return element by list element number
x[#element_number]
  
# NOTE: The above example, a vector is retrieved.
```

```R
# Preserve the properties of matrix (ie return a matrix)
x[#row,#col,drop = FALSE]
```

**Multiple Elements**

```R
# Return whole row
x[#row, ]
```

```R
# Return whole column
x[ , #col]
```

*NOTE:* `drop = FALSE` also works for multiple elements

### Removing Missing Values

```R
bad <- is.na(x)
> x[!bad]
```

 *i.e.* sublist of entries that aren't NA using a logical vector

```R
# Check multiple lists for missing values
> good <- complete.cases(x,y)
> x[good]
> y[good]
```

*good*  is a logical list that consists of the combined NA comparison of the two vectors

## Partial Matching

```R
#return partially matched objects
x$a
x[["a", exact = FALSE]]
```

## Vector Operations

```R
# Element wise multiplication
x * y

# Element wise division
x / y

# True matrix multiplication
x %*% y
```

## Reading Large Datasets

Don't use `read.table` if the dataset will be larger then available ram

```R
# Specify the arguments - ColClasses
colClasses = c("<|datatype1|>","<|datatype2|>",etc)
# Determine classes from sample size
inital <- read.table("data.txt", nrows=100)
classes <- sapply(initial,class)
AllData <- read.table("data.txt", colClasses = classes)

# Here we read the first 100 rows of the text file. Determine the classes then declare the classes when we import all the rows in the 3rd line.
```

```R
# Determine number of lines
system(wc <|file-path|>)
       
# NOTE: using unix command wc       
```

### Determining Memory Requirements

1,500,000 rows
120 columns
All entries are numeric (8 bytes)
$$
\text{The above information produces a rough guess of:}
\\
1,500,000 * 120 * 8 \text{ bytes} 
\\
= 1,440,000,000,000 \text{ bytes} 
\\
\text{ STEP: divide by } 2^{20} \text{for MB}
\\
= 1,373.29 MB
\\
\text{Step: divide by  } 2^{10} \text{for GB}
\\
= 1.34 \text{GB}
$$
==Rule of thumb==: double the estimate, to consider overhead




# Control Structures 

```R
# If 
if (<condition>){
  
}else if(<condition>){
  
}else{
  
}
```

*Assign control result to var*

```R
# Can also assign it to a variable
y <- if(){
  <return value>
}  

# alternativly
if(){
  y <- <value>
}else{
  y <- <value>
}
```

## Loop Structures

### For Loop

```R
for (i in <vector>){
}

#Example
for (i in 1:3){
  
}
```

*Nested Loops*

```R
# Example: Going through a matrix
x <- matrix(1:6,2,3)

for(i in seq_len(nrow(x))){
  for(j in seq_len(ncol(x))){
    println(x[i,j])
  }
}
```

### While Loop

```R
while(<condition>){
  
}
```

### Repeat

```R
# Repeates untill break
repeate{
  if (<condition>){
    break
  }
}
```

### Skipping iteration

```R
for (i in <vector>){
  if(<condition>){
    next
  }
}
```

# Functions

```R
# Example: Defining a function
# Return vector with values above n
# Default value of n=10
above <- function(x,n = 10){
  use <- x > n
  x[use]
}
```

## Argument Matching

Order of argument matching

1. Exact match for named argument
2. Partial Match
3. Position Match

```R
# Example
args(lm)
function (formula, data, subset, weights, na.action, method = "qr", 
    model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, 
    contrasts = NULL, offset, ...) 
```

***Note:*** The above function requires the user to input the first 5 arguments. The order of the arguments inputted does not matter as long as they are named. e.g. 

```R
lm(data=<somedata>,formula=x*y,na.action=false,weight=2,subset=<somesubset>)
```

 **Lazy Loading** Arguments are lazy loaded. They are evaluated only as needed.

```R
# No Error will occure
f <- function(a,b){
	a^2
}
> f(2)
> 4
```

```R
# Error will only occure once line 4 is hit
f <- function(a,b){
	a^2
	b+2
}
> f(2)
> 4
# Error: argument "b" is missing
```

**`...`Arguments** 

Indicate a variable number of arguments that are passed onto other functions.

- Often used when extending another function - avoid copying entire list of original arguments. 
- More then one argument that we don't know a user will input. Like `paste`

```R
# Example
myplot <- function(x,y,type="l",...){}
  plot(x,y,type=type,...)
}
```

*Note:* 

1) Arguments after `...` must be explicitly matched. If this is not done, R will assume the value is part of the `...` arguments.  

2) `...` can be left empty when calling a function

# Lexical Scoping 

==Note== R uses *Lexical Scoping* - the values of free variables are searched for in the environment in which the function was defined. 

If R encounters a free variable, it will then travel up the environment tree looking for the variable. 
eg. $\text{Function Env defined in} \rightarrow \text{Parent Env} \rightarrow \text{Top-Level Env : usually global / workspace Env}\rightarrow \\ \text{Further down the environment} \rightarrow \text{Empty Env}$ 

$\text{Parent Env}$: Environment function was called in  

Once the $\text{Empty Env}$ has been reached then an error is thrown.

```R
# Ordered search List for Symbols R looks through
Search()
```

==Note== User can define what order packages get loaded. New package loaded will be loaded one spot bellow the *work environment*. Everything else is moved one spot down. 
==Consequence:== When writing code, we can not assume how scoping will behave.

# Looping functions

**Example:** Dealing with function *arguments*
i.e. just add them to the next argument spaces  

```
lapply(x,runif, min = 0, max = 1)
```

## `lapply` - loop over a list and evaluate a function on each element

- always returns a list

## `sapply` - same as `lapply` but try to simplify the result

- if all the elements are of the size 1 -> returns a ***vector***
- if all the elements are of the same size -> returns a ***matrix***
- *else* returns a ***list***

## `apply` - apply a function over a the margins of an array

- apply function to ***rows*** & ***columns***
- Also works on whole arrays
- not faster then using a convention loop

```R
# cal the mean of each col of a matrix
x <- matrix(rnorm(200),20,10) #20 rows, 10 cols dim(20,10)

apply(x,2,mean) #2 -> keep the 2nd dim and colapse the 1st dim into the function -> ie find the mean for each col

#find mean of each row
apply(x,1,mean)
```

```R
# dealing with higher dimensions - 3D cube
a <- arrray(rnorm(2 * 2 * 10), c(2,2,10))

# find the mean along the 3rd dimension, keeping the 1st an 2nd dim
apply(a,c(1,2),mean)

# can also use more optimised function
rowMeans(a, dims =2)
```

### Optimized apply functions

The functions have been optimized to run ***much*** faster then apply 

*  `rowSums`
*  `rowMeans`
*  `colSums`
*  `colMeans`

## `mapply` - multivariate version of `lapply`

This applied a function parallel over a set of arguments

```R
#Basic example
> mapply(rep,1:4,4:1)
[[1]]
[1] 1 1 1 1

[[2]]
[1] 2 2 2

[[3]]
[1] 3 3

[[4]]
[1] 4
```

***Vectorization of a function***

```R
#Example
noise <- function(n,mean sd){
  rnorm(n,mean,sd)
}

#We can do the following with mapply
list(noise(1,1,2), noise(2,2,2),noise(3,3,2))

# with mapply
mapply(noise,1:3,1:3,2) #changing the n and mean for 3 different results
```

## `tapply`  - apply a function over subsets of a vector

In the background think of the list being split into groups with `split`

```R
# take 3 group normals
x <- c(rnorm(10),runif(10),rnorm(10,1))
f <- gl(3,10) 

tapply(x,f,mean)
         1          2          3 
0.07089416 0.40943126 0.71821110 

# the same as 
lapply(split(x,f),mean)
```

## `split` 

* Divides the data in the vector x into the groups defined by f

==NOTE== has `drop` argument that drops empty levels that are empty

```R
# Spliting to 3 groups
x <- c(rnorm(10),runif(10),rnorm(10,1))
f <- gl(3,10) 

split(x,f)
$`1`
 [1] -1.0510602  0.6390667 -1.1844335  1.4694339 -0.5913725
 [6]  0.4665564 -1.4135527  1.9782572  0.6352339 -0.2391876

$`2`
 [1] 0.250213059 0.468191714 0.555302177 0.495414285 0.162347914
 [6] 0.404373503 0.418992073 0.450538643 0.887675458 0.001263779

$`3`
 [1]  1.6352665  1.0328139  0.5006926 -0.9504895  0.6489016
 [6]  0.6262256  1.9785490  2.2131524 -0.6940379  0.1910369
```

More complicated example

```R
# split the dataframe according to months and find the means for each month
s <- split(airquality, airquality$Month)

sapply(s,function(x) colMeans(x[,c("Ozone","Solar.R","Wind")]), na.rm=TRUE) 
```

### Splitting on >1 levels

Spit according to the combination of multiple factors 

```R
x <- rnorm(10)
f1 <- gl(2,5) # 2 levels
f2 <- gl(5,2) # 5 levels

interaction(f1,f2) # all combinations of different levels
 [1] 1.1 1.1 1.2 1.2 1.3 2.3 2.4 2.4 2.5 2.5
Levels: 1.1 2.1 1.2 2.2 1.3 2.3 1.4 2.4 1.5 2.5

> split(x,list(f1,f2))
$`1.1`
[1] -0.5988166 -1.4389235
$`2.1`
numeric(0)
$`1.2`
[1] -1.3074090  0.4250326
$`2.2`
numeric(0)
#...etc
```

## Anonymous functions in loop functions

The above listed loop functions make heavy use of *anonymous functions*

```R
# function that gets first col for each matrix
x <- list(1:4,2,2), b = matrix(1:6,3,2)

lapply(x, function(elt) elt[,1])
```

# Debugging

Logging types

* `message`
* `warning`
* `error`
* `condition` - generic concept that programmer can extend to make their own logging type\

## Tools

### `traceback`  

prints out function call stack

```R
> mean(x)
Error
> traceback() #has to be executed immediately after code is executed 
l: mean(x)
```

### `debug` 

flags a function for "debug" mode, step through function line at a time> 

```R
> debug(lm)
> lm(y - x)
#debugger executes
# press "n" for next line
```

### `browser `

Suspends execution of function wherever it is called and puts function into debug mode

### `trace`

Allows you to insert debugging code into a function at specific places (without editing the function it self)

### `recover` 

Allows you to modify the error behavior so that you can browse the function call stack

```R
> options(error = recover) #global option
> read.csv("no file")
#debuger exetures but offers options of what to do next
```

# other 

## Creating function where an assignment occurs but nothing is printed 

```R
f1 <- function(x) x
f2 <- function(x) invisible(x)
  
y <- f1(1)
>	1
y <- f2(1) #nothing returned 

y
> 1
```
## formatting outputs of loop functions / formatting lists `unlist`

[Understanding lapply()](https://www.coursera.org/learn/r-programming/discussions/weeks/3/threads/qcv_orZHEeWF2Q53QdZUbw)

[A few pointers for assignment 3](https://www.coursera.org/learn/r-programming/discussions/weeks/4/threads/znVFbLgpEeWlQwoU9G612w)

```R
# say we want somthing like this
                                             hospital state
AK                        FAIRBANKS MEMORIAL HOSPITAL    AK
AL                          SPRINGHILL MEDICAL CENTER    AL
AR          BAPTIST HEALTH MEDICAL CENTER-LITTLE ROCK    AR
AZ                     CARONDELET ST JOSEPHS HOSPITAL    AZ
CA                          HUNTINGTON BEACH HOSPITAL    CA
CO                               MCKEE MEDICAL CENTER    CO
CT                         ROCKVILLE GENERAL HOSPITAL    CT
DC                                               <NA>    DC

# but our lapply produces somthing like this
$AK
[1] "FAIRBANKS MEMORIAL HOSPITAL"

$AL
[1] "SPRINGHILL MEDICAL CENTER"

$AR
[1] "BAPTIST HEALTH MEDICAL CENTER-LITTLE ROCK"

$AZ
[1] "CARONDELET ST JOSEPHS HOSPITAL"

$CA
[1] "HUNTINGTON BEACH HOSPITAL"

$CO
[1] "MCKEE MEDICAL CENTER"

$CT
[1] "ROCKVILLE GENERAL HOSPITAL"

# HOW DO WE FORMAT this list?
```

```R
  # USE  unlist
  ranks <- lapply(split(orderedDF,orderedDF$State),function(x){
    
    rank <- num  
    if (class(num) == "character"){
      if (num == "best"){
        rank <- 1
      }else if (num == "worst"){
        rank <- dim(x)[1]
      }
    }
    x[rank,"Hospital.Name"]#["Hospital.Name"]
  })
  
  output <- data.frame(hospital=unlist(x,use.names = FALSE),state=names(ranks),row.names=names(ranks))
```




# `str` function

# Generating Random Numbers

==Important== Setting the random seed number ***ensures reproducibility!***
`set.seed(<number>)` Make sure that functions you run after setting the seed do not change the seed.

For probability functions there are usually 4 functions associated with them:

* **d** - density
* **r** - random number generation
* **p** - cumulative distribution 
* **q** - quantile function 

**Example**

`rnorm` - generate ***random Normal variates*** with given *norm & SD*

`dnorm` - evaluate the ***Normal probability density*** (with a given mean/SD) at a point (or vector of points)

`pnorm` - evaluate the ***cumulative distribution*** function from a *Normal Distribution* 

`rpois` - ***generate random Poisson variants*** with a *given rate*

## Normal Distribution

```R
dnorm(x, mean = 0, sd = 1, log = FALSE)
pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
rnorm(n, mean = 0, sd = 1)
```

**Arguments**

`x, q` - vector of quantiles.
`p` - vector of probabilities.
`n` - number of observations. If length(n) > 1, the length is taken to be the number required.

If arguments aren't specified: `mean=0` & `sd=1`

==Note==
If $\Phi$ is the cumulative distribution function for a standard Normal distribution, then $\text{pnorm(q)} = \Phi(q)$ and $\text{qnorm(p)} = \Phi^-1(p)$

## Poisson Data

```R
# Example
ppois(2,2) # probability x <= 2 with distribution 2
```

# Simulating a Linear Model

## Example 1

Say we want to simulate from the following linear model:

$y = \beta_0 + \beta_1x+\epsilon $ 
where $\epsilon \sim N(0,2^2)$ noise with standard distribution with standard deviation of 2
Assume $x \sim N(0,1^2)$ standard *normal* distribution
 $\beta_0 = 0.5$ , $\beta_1 =2$

```R
# Example
set.seed(20)
x <- rnorm(100)
e <- rnomr(100,0,2)
y <- 0.5 + 2*x + e
```

**Plot**

![linearModel](C:\Users\jeroen.schmidt\Documents\Notes\Coursera Notes\R Language\Images/linearModel.PNG)

## Example 2

We can generate similar data for **binary data** by using the binomial function `rbinom`?

```R
e <- rnorm(100,0,2)
y <- 0.5 + 2*x + e
set.seed(20)
x <- rbinom(100,1,0.5)
e <- rnorm(100,0,2)
y <- 0.5 + 2*x + e
plot(x,y)
```

**Plot**

![binarySimulation](C:\Users\jeroen.schmidt\Documents\Notes\Coursera Notes\R Language\Images/binarySimulation.PNG)

## Example 3 - Generalized Linear Model

Say we want to simulate a linear model with a *poisson* distribution.
i.e. $Y \sim \text{Poisson}(\mu)$
$\log(\mu) = \beta_0 + \beta_1x$ where $\beta_0 = 0.5$ and $\beta_1 =0.3$

```R
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5 + 0.3 * x
y <- rpois(100,exp(log.mu))
```

**Plot**

![PoissonSimulation](C:\Users\jeroen.schmidt\Documents\Notes\Coursera Notes\R Language\Images/PoissonSimulation.PNG)

# Random Sampling

```R
# sample 4 values with out replacment
sample(1:10, 4)

# sample with replacment - allows repeats
sample(1:10, replace = TRUE)
```

==NOTE== `sample` changes the seed every time it runs.  Redeclaring the seed every time you run sample resolves this. `set.seed(42); sample(LETTERS, 5)`

# Profiling R Code

*Profiling* is a systematic way of examining how much time is spend on sections of a program.

> Premature optimization is the root of all evil
>
> -Donal Knuth

> Design first, then optimize

 ## Timing

`system.time()` and `proc_time` are used to time code execution times. 

**Two concepts to know**

`Elapse time` - amount of time from start of execution till results returned

`user time` - amount of time the cpu actively handles the program

*Possible outcomes*

`user time` > `elapsed time` : machine has multi core processors 

`elapsed time` >`user time`  : cpu is being occupied by other processes. 

```R
# Example
system.time(<function>)
  
# Longer expressions -> use anon-functions
system.time({
  <code>
})
```

## The Profiler

What if we don't know where to look for bottle necks? We use the *R Profiler* `Rprof()` 
For summaries use `summaryRprof()`

==NOTE== Do not use `system.time()` with `Rprof()`

The default sampling interval is 0.02 seconds, *if the code runs very quickly the profiler isnt that useful*. Use it with code that takes an order of seconds to run.

### `summaryRprof()`

**Methods that normalize the data**

* `by.total` - divides time spend in each function by the total run time
* `by.self` - does the same but 1st subtracts out time spent in functions above in the call stack

```R
# example
Rprof("name of profile")
# some code to be profiled
Rprof(NULL) # stops profiler
# some code NOT to be profiled

Rprof("name of profile", append=TRUE)
# some code to be profiled
Rprof(NULL) # stops profiler
 
# summarize the results
summaryRprof("name of profile")
```

==NOTE== `C` and `Fortran` code is not profiled



